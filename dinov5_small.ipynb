{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiobhJ-7rQeb",
    "outputId": "5489b700-ac4a-4289-bad0-3cfb9eb8714e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import faiss\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os # --- NEW --- Import os to get CPU count\n",
    "import matplotlib.pyplot as plt  # For plotting loss and k-NN accuracy\n",
    "\n",
    "class DINOTarget:\n",
    "    def __init__(self, dim, momentum=0.9, teacher_temp=0.07, device=\"cuda\"):\n",
    "        # DINO paper uses teacher_temp=0.07 (not 0.04)\n",
    "        self.center = torch.zeros(1, dim, device=device)\n",
    "        self.momentum = momentum\n",
    "        self.teacher_temp = teacher_temp\n",
    "\n",
    "    def __call__(self, teacher_logits):\n",
    "        # center\n",
    "        t = teacher_logits - self.center\n",
    "        # sharpen\n",
    "        t = t / self.teacher_temp\n",
    "        t = F.softmax(t, dim=-1)\n",
    "        # update center\n",
    "        self.center = self.center * self.momentum + (1 - self.momentum) * teacher_logits.mean(dim=0, keepdim=True)\n",
    "        return t.detach()\n",
    "\n",
    "def load_checkpoint(checkpoint_path, student, teacher, student_head, teacher_head, optimizer=None, device=\"cuda\"):\n",
    "    \"\"\"Load a checkpoint and restore model states\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    student.load_state_dict(checkpoint['student_state_dict'])\n",
    "    teacher.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "    student_head.load_state_dict(checkpoint['student_head_state_dict'])\n",
    "    teacher_head.load_state_dict(checkpoint['teacher_head_state_dict'])\n",
    "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}, k-NN acc: {checkpoint.get('knn_acc', 'N/A')}\")\n",
    "    return checkpoint['epoch'], checkpoint.get('knn_acc', 0.0)\n",
    "\n",
    "def update_teacher(student, teacher, student_head, teacher_head, ema_m):\n",
    "    # Update backbone parameters\n",
    "    for s_param, t_param in zip(student.parameters(), teacher.parameters()):\n",
    "        t_param.data = ema_m * t_param.data + (1 - ema_m) * s_param.data\n",
    "    # Update projection head parameters\n",
    "    for s_param, t_param in zip(student_head.parameters(), teacher_head.parameters()):\n",
    "        t_param.data = ema_m * t_param.data + (1 - ema_m) * s_param.data\n",
    "\n",
    "def dino_loss(student_logits, teacher_probs, student_temp=0.1):\n",
    "    # student_logits: raw output of student projection head (NOT normalized)\n",
    "    # teacher_probs: output of teacher after centering and sharpening\n",
    "    # DINO paper uses student_temp=0.1 (which we have)\n",
    "    # Apply temperature scaling to student logits before log_softmax\n",
    "    student_log_probs = F.log_softmax(student_logits / student_temp, dim=-1)\n",
    "    loss = -(teacher_probs * student_log_probs).sum(dim=-1).mean()\n",
    "    return loss\n",
    "\n",
    "def koleo_loss(embeddings, k=3, eps=1e-8):\n",
    "    \"\"\"\n",
    "    KoLeo (Kozachenko-Leonenko) regularization loss.\n",
    "    Encourages diverse representations by maximizing entropy using k-NN distances.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Tensor of shape (batch_size, embed_dim) - normalized embeddings\n",
    "        k: Number of nearest neighbors to use\n",
    "        eps: Small epsilon for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        KoLeo loss (negative entropy, so we minimize it to maximize entropy)\n",
    "    \"\"\"\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    # embeddings: (B, D), compute (B, B) distance matrix\n",
    "    dot_product = torch.mm(embeddings, embeddings.t())  # (B, B)\n",
    "    # For normalized vectors, dot product = cosine similarity\n",
    "    # Distance = 1 - cosine_similarity (for normalized vectors)\n",
    "    distances = 1 - dot_product  # (B, B)\n",
    "    \n",
    "    # Set diagonal to large value (self-distance should be ignored)\n",
    "    distances.fill_diagonal_(float('inf'))\n",
    "    \n",
    "    # Find k nearest neighbors for each sample\n",
    "    # Get k smallest distances (excluding self)\n",
    "    knn_distances, _ = torch.topk(distances, k=k, dim=1, largest=False)  # (B, k)\n",
    "    \n",
    "    # KoLeo entropy estimate: -log(knn_distance) averaged\n",
    "    # We want to maximize entropy, so we minimize negative entropy\n",
    "    # Add eps to avoid log(0)\n",
    "    log_distances = torch.log(knn_distances + eps)  # (B, k)\n",
    "    koleo = -log_distances.mean()  # Negative entropy (we minimize this)\n",
    "    \n",
    "    return koleo\n",
    "\n",
    "def train_dino(train_loader, student, teacher, student_head, teacher_head,\n",
    "               optimizer, device=\"cuda\", num_epochs=50, ema_m=0.996, knn_eval_freq=5,\n",
    "               warmup_epochs=10, save_dir=\"./checkpoints\", save_freq=10, koleo_weight=0.1,\n",
    "               knn_train_loader=None, knn_test_loader=None, resume_from=None):\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    if save_dir:\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize or resume from checkpoint\n",
    "    start_epoch = 0\n",
    "    best_knn_acc = 0.0\n",
    "    losses = []\n",
    "    knn_accuracies = []\n",
    "    epochs_evaluated = []\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    \n",
    "    # Check for resume checkpoint\n",
    "    resume_checkpoint_path = None\n",
    "    if resume_from:\n",
    "        resume_checkpoint_path = resume_from\n",
    "    elif save_dir:\n",
    "        # Check for latest checkpoint\n",
    "        latest_checkpoint = Path(save_dir) / \"checkpoint_latest.pt\"\n",
    "        if latest_checkpoint.exists():\n",
    "            resume_checkpoint_path = str(latest_checkpoint)\n",
    "    \n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        print(f\"\\nðŸ”„ Resuming training from {resume_checkpoint_path}...\")\n",
    "        checkpoint = torch.load(resume_checkpoint_path, map_location=device, weights_only=False)\n",
    "        student.load_state_dict(checkpoint['student_state_dict'])\n",
    "        teacher.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "        student_head.load_state_dict(checkpoint['student_head_state_dict'])\n",
    "        teacher_head.load_state_dict(checkpoint['teacher_head_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'scaler_state_dict' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_knn_acc = checkpoint.get('best_knn_acc', 0.0)\n",
    "        losses = checkpoint.get('losses', [])\n",
    "        knn_accuracies = checkpoint.get('knn_accuracies', [])\n",
    "        epochs_evaluated = checkpoint.get('epochs_evaluated', [])\n",
    "        print(f\"âœ“ Resumed from epoch {start_epoch}, best k-NN acc: {best_knn_acc:.2f}%\")\n",
    "    else:\n",
    "        # Initialize teacher as a copy of student\n",
    "        teacher.load_state_dict(student.state_dict())\n",
    "        teacher.eval()\n",
    "        # Initialize teacher_head as a copy of student_head\n",
    "        teacher_head.load_state_dict(student_head.state_dict())\n",
    "        print(\"âœ“ Starting fresh training\")\n",
    "    \n",
    "    dino_target = DINOTarget(dim=teacher_head.mlp[-1].out_features, device=device)\n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        # Restore DINO target center if available\n",
    "        if 'dino_target_center' in checkpoint:\n",
    "            dino_target.center = checkpoint['dino_target_center'].to(device)\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    # Use constant learning rate of 1e-4 (no scheduler)\n",
    "    constant_lr = 1e-4\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = constant_lr\n",
    "    \n",
    "    # Initialize plot for real-time updates\n",
    "    fig, ax1, ax2 = None, None, None\n",
    "    plot_path = None\n",
    "    if save_dir:\n",
    "        plot_path = f\"{save_dir}/training_curves.png\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        plt.ion()  # Turn on interactive mode\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)  # Track loss for plotting\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Update plot in real-time\n",
    "        if save_dir and len(losses) > 0 and fig is not None:\n",
    "            ax1.clear()\n",
    "            ax1.plot(range(1, len(losses) + 1), losses, 'b-', linewidth=2)\n",
    "            ax1.set_xlabel('Epoch', fontsize=12)\n",
    "            ax1.set_ylabel('Loss', fontsize=12)\n",
    "            ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.set_xlim([1, max(len(losses), num_epochs)])\n",
    "            \n",
    "            if len(knn_accuracies) > 0:\n",
    "                ax2.clear()\n",
    "                ax2.plot(epochs_evaluated, knn_accuracies, 'r-o', linewidth=2, markersize=6)\n",
    "                ax2.set_xlabel('Epoch', fontsize=12)\n",
    "                ax2.set_ylabel('k-NN Accuracy (%)', fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.set_xlim([1, num_epochs])\n",
    "                if len(knn_accuracies) > 0:\n",
    "                    ax2.set_ylim([0, max(100, max(knn_accuracies) * 1.1)])\n",
    "            else:\n",
    "                ax2.clear()\n",
    "                ax2.text(0.5, 0.5, 'No k-NN evaluations yet', \n",
    "                        ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "            plt.pause(0.01)  # Small pause to update display\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        # DINO paper: evaluate on teacher EMA model only, using [cls] token\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            if knn_train_loader is not None and knn_test_loader is not None:\n",
    "                knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "                knn_accuracies.append(knn_acc)\n",
    "                epochs_evaluated.append(epoch + 1)\n",
    "                print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scaler_state_dict': scaler.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'best_knn_acc': best_knn_acc,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                        'losses': losses,\n",
    "                        'knn_accuracies': knn_accuracies,\n",
    "                        'epochs_evaluated': epochs_evaluated,\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\", _use_new_zipfile_serialization=False)\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Save latest checkpoint every epoch (for resuming)\n",
    "        if save_dir:\n",
    "            latest_checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(latest_checkpoint, f\"{save_dir}/checkpoint_latest.pt\", _use_new_zipfile_serialization=False)\n",
    "        \n",
    "        # Periodic checkpoint saving (numbered checkpoints)\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\", _use_new_zipfile_serialization=False)\n",
    "            print(f\"  â†’ Saved checkpoint: checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Final plot update\n",
    "    if save_dir and len(losses) > 0 and fig is not None:\n",
    "        plt.ioff()  # Turn off interactive mode\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Final training curves saved to {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    if save_dir:\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize or resume from checkpoint\n",
    "    start_epoch = 0\n",
    "    best_knn_acc = 0.0\n",
    "    losses = []\n",
    "    knn_accuracies = []\n",
    "    epochs_evaluated = []\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    \n",
    "    # Check for resume checkpoint\n",
    "    resume_checkpoint_path = None\n",
    "    if resume_from:\n",
    "        resume_checkpoint_path = resume_from\n",
    "    elif save_dir:\n",
    "        # Check for latest checkpoint\n",
    "        latest_checkpoint = Path(save_dir) / \"checkpoint_latest.pt\"\n",
    "        if latest_checkpoint.exists():\n",
    "            resume_checkpoint_path = str(latest_checkpoint)\n",
    "    \n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        print(f\"\\nðŸ”„ Resuming training from {resume_checkpoint_path}...\")\n",
    "        checkpoint = torch.load(resume_checkpoint_path, map_location=device, weights_only=False)\n",
    "        student.load_state_dict(checkpoint['student_state_dict'])\n",
    "        teacher.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "        student_head.load_state_dict(checkpoint['student_head_state_dict'])\n",
    "        teacher_head.load_state_dict(checkpoint['teacher_head_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'scaler_state_dict' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_knn_acc = checkpoint.get('best_knn_acc', 0.0)\n",
    "        losses = checkpoint.get('losses', [])\n",
    "        knn_accuracies = checkpoint.get('knn_accuracies', [])\n",
    "        epochs_evaluated = checkpoint.get('epochs_evaluated', [])\n",
    "        print(f\"âœ“ Resumed from epoch {start_epoch}, best k-NN acc: {best_knn_acc:.2f}%\")\n",
    "    else:\n",
    "        # Initialize teacher as a copy of student\n",
    "        teacher.load_state_dict(student.state_dict())\n",
    "        teacher.eval()\n",
    "        # Initialize teacher_head as a copy of student_head\n",
    "        teacher_head.load_state_dict(student_head.state_dict())\n",
    "        print(\"âœ“ Starting fresh training\")\n",
    "    \n",
    "    dino_target = DINOTarget(dim=teacher_head.mlp[-1].out_features, device=device)\n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        # Restore DINO target center if available\n",
    "        if 'dino_target_center' in checkpoint:\n",
    "            dino_target.center = checkpoint['dino_target_center'].to(device)\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    # Use constant learning rate of 1e-4 (no scheduler)\n",
    "    constant_lr = 1e-4\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = constant_lr\n",
    "    \n",
    "    # Initialize plot for real-time updates\n",
    "    fig, ax1, ax2 = None, None, None\n",
    "    plot_path = None\n",
    "    if save_dir:\n",
    "        plot_path = f\"{save_dir}/training_curves.png\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        plt.ion()  # Turn on interactive mode\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)  # Track loss for plotting\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Update plot in real-time\n",
    "        if save_dir and len(losses) > 0 and fig is not None:\n",
    "            ax1.clear()\n",
    "            ax1.plot(range(1, len(losses) + 1), losses, 'b-', linewidth=2)\n",
    "            ax1.set_xlabel('Epoch', fontsize=12)\n",
    "            ax1.set_ylabel('Loss', fontsize=12)\n",
    "            ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.set_xlim([1, max(len(losses), num_epochs)])\n",
    "            \n",
    "            if len(knn_accuracies) > 0:\n",
    "                ax2.clear()\n",
    "                ax2.plot(epochs_evaluated, knn_accuracies, 'r-o', linewidth=2, markersize=6)\n",
    "                ax2.set_xlabel('Epoch', fontsize=12)\n",
    "                ax2.set_ylabel('k-NN Accuracy (%)', fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.set_xlim([1, num_epochs])\n",
    "                if len(knn_accuracies) > 0:\n",
    "                    ax2.set_ylim([0, max(100, max(knn_accuracies) * 1.1)])\n",
    "            else:\n",
    "                ax2.clear()\n",
    "                ax2.text(0.5, 0.5, 'No k-NN evaluations yet', \n",
    "                        ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "            plt.pause(0.01)  # Small pause to update display\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        # DINO paper: evaluate on teacher EMA model only, using [cls] token\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            if knn_train_loader is not None and knn_test_loader is not None:\n",
    "                knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "                knn_accuracies.append(knn_acc)\n",
    "                epochs_evaluated.append(epoch + 1)\n",
    "                print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scaler_state_dict': scaler.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'best_knn_acc': best_knn_acc,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                        'losses': losses,\n",
    "                        'knn_accuracies': knn_accuracies,\n",
    "                        'epochs_evaluated': epochs_evaluated,\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\", _use_new_zipfile_serialization=False)\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Save latest checkpoint every epoch (for resuming)\n",
    "        if save_dir:\n",
    "            latest_checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(latest_checkpoint, f\"{save_dir}/checkpoint_latest.pt\", _use_new_zipfile_serialization=False)\n",
    "        \n",
    "        # Periodic checkpoint saving (numbered checkpoints)\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\", _use_new_zipfile_serialization=False)\n",
    "            print(f\"  â†’ Saved checkpoint: checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Final plot update\n",
    "    if save_dir and len(losses) > 0 and fig is not None:\n",
    "        plt.ioff()  # Turn off interactive mode\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Final training curves saved to {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    if save_dir:\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize or resume from checkpoint\n",
    "    start_epoch = 0\n",
    "    best_knn_acc = 0.0\n",
    "    losses = []\n",
    "    knn_accuracies = []\n",
    "    epochs_evaluated = []\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    \n",
    "    # Check for resume checkpoint\n",
    "    resume_checkpoint_path = None\n",
    "    if resume_from:\n",
    "        resume_checkpoint_path = resume_from\n",
    "    elif save_dir:\n",
    "        # Check for latest checkpoint\n",
    "        latest_checkpoint = Path(save_dir) / \"checkpoint_latest.pt\"\n",
    "        if latest_checkpoint.exists():\n",
    "            resume_checkpoint_path = str(latest_checkpoint)\n",
    "    \n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        print(f\"\\nðŸ”„ Resuming training from {resume_checkpoint_path}...\")\n",
    "        checkpoint = torch.load(resume_checkpoint_path, map_location=device, weights_only=False)\n",
    "        student.load_state_dict(checkpoint['student_state_dict'])\n",
    "        teacher.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "        student_head.load_state_dict(checkpoint['student_head_state_dict'])\n",
    "        teacher_head.load_state_dict(checkpoint['teacher_head_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'scaler_state_dict' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_knn_acc = checkpoint.get('best_knn_acc', 0.0)\n",
    "        losses = checkpoint.get('losses', [])\n",
    "        knn_accuracies = checkpoint.get('knn_accuracies', [])\n",
    "        epochs_evaluated = checkpoint.get('epochs_evaluated', [])\n",
    "        print(f\"âœ“ Resumed from epoch {start_epoch}, best k-NN acc: {best_knn_acc:.2f}%\")\n",
    "    else:\n",
    "        # Initialize teacher as a copy of student\n",
    "        teacher.load_state_dict(student.state_dict())\n",
    "        teacher.eval()\n",
    "        # Initialize teacher_head as a copy of student_head\n",
    "        teacher_head.load_state_dict(student_head.state_dict())\n",
    "        print(\"âœ“ Starting fresh training\")\n",
    "    \n",
    "    dino_target = DINOTarget(dim=teacher_head.mlp[-1].out_features, device=device)\n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        # Restore DINO target center if available\n",
    "        if 'dino_target_center' in checkpoint:\n",
    "            dino_target.center = checkpoint['dino_target_center'].to(device)\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    # Use constant learning rate of 1e-4 (no scheduler)\n",
    "    constant_lr = 1e-4\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = constant_lr\n",
    "    \n",
    "    # Initialize plot for real-time updates\n",
    "    fig, ax1, ax2 = None, None, None\n",
    "    plot_path = None\n",
    "    if save_dir:\n",
    "        plot_path = f\"{save_dir}/training_curves.png\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        plt.ion()  # Turn on interactive mode\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)  # Track loss for plotting\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Update plot in real-time\n",
    "        if save_dir and len(losses) > 0 and fig is not None:\n",
    "            ax1.clear()\n",
    "            ax1.plot(range(1, len(losses) + 1), losses, 'b-', linewidth=2)\n",
    "            ax1.set_xlabel('Epoch', fontsize=12)\n",
    "            ax1.set_ylabel('Loss', fontsize=12)\n",
    "            ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.set_xlim([1, max(len(losses), num_epochs)])\n",
    "            \n",
    "            if len(knn_accuracies) > 0:\n",
    "                ax2.clear()\n",
    "                ax2.plot(epochs_evaluated, knn_accuracies, 'r-o', linewidth=2, markersize=6)\n",
    "                ax2.set_xlabel('Epoch', fontsize=12)\n",
    "                ax2.set_ylabel('k-NN Accuracy (%)', fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.set_xlim([1, num_epochs])\n",
    "                if len(knn_accuracies) > 0:\n",
    "                    ax2.set_ylim([0, max(100, max(knn_accuracies) * 1.1)])\n",
    "            else:\n",
    "                ax2.clear()\n",
    "                ax2.text(0.5, 0.5, 'No k-NN evaluations yet', \n",
    "                        ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "            plt.pause(0.01)  # Small pause to update display\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        # DINO paper: evaluate on teacher EMA model only, using [cls] token\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            if knn_train_loader is not None and knn_test_loader is not None:\n",
    "                knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "                knn_accuracies.append(knn_acc)\n",
    "                epochs_evaluated.append(epoch + 1)\n",
    "                print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scaler_state_dict': scaler.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'best_knn_acc': best_knn_acc,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                        'losses': losses,\n",
    "                        'knn_accuracies': knn_accuracies,\n",
    "                        'epochs_evaluated': epochs_evaluated,\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\", _use_new_zipfile_serialization=False)\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Save latest checkpoint every epoch (for resuming)\n",
    "        if save_dir:\n",
    "            latest_checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(latest_checkpoint, f\"{save_dir}/checkpoint_latest.pt\", _use_new_zipfile_serialization=False)\n",
    "        \n",
    "        # Periodic checkpoint saving (numbered checkpoints)\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\", _use_new_zipfile_serialization=False)\n",
    "            print(f\"  â†’ Saved checkpoint: checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Final plot update\n",
    "    if save_dir and len(losses) > 0 and fig is not None:\n",
    "        plt.ioff()  # Turn off interactive mode\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Final training curves saved to {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    if save_dir:\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize or resume from checkpoint\n",
    "    start_epoch = 0\n",
    "    best_knn_acc = 0.0\n",
    "    losses = []\n",
    "    knn_accuracies = []\n",
    "    epochs_evaluated = []\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    \n",
    "    # Check for resume checkpoint\n",
    "    resume_checkpoint_path = None\n",
    "    if resume_from:\n",
    "        resume_checkpoint_path = resume_from\n",
    "    elif save_dir:\n",
    "        # Check for latest checkpoint\n",
    "        latest_checkpoint = Path(save_dir) / \"checkpoint_latest.pt\"\n",
    "        if latest_checkpoint.exists():\n",
    "            resume_checkpoint_path = str(latest_checkpoint)\n",
    "    \n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        print(f\"\\nðŸ”„ Resuming training from {resume_checkpoint_path}...\")\n",
    "        checkpoint = torch.load(resume_checkpoint_path, map_location=device, weights_only=False)\n",
    "        student.load_state_dict(checkpoint['student_state_dict'])\n",
    "        teacher.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "        student_head.load_state_dict(checkpoint['student_head_state_dict'])\n",
    "        teacher_head.load_state_dict(checkpoint['teacher_head_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'scaler_state_dict' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_knn_acc = checkpoint.get('best_knn_acc', 0.0)\n",
    "        losses = checkpoint.get('losses', [])\n",
    "        knn_accuracies = checkpoint.get('knn_accuracies', [])\n",
    "        epochs_evaluated = checkpoint.get('epochs_evaluated', [])\n",
    "        print(f\"âœ“ Resumed from epoch {start_epoch}, best k-NN acc: {best_knn_acc:.2f}%\")\n",
    "    else:\n",
    "        # Initialize teacher as a copy of student\n",
    "        teacher.load_state_dict(student.state_dict())\n",
    "        teacher.eval()\n",
    "        # Initialize teacher_head as a copy of student_head\n",
    "        teacher_head.load_state_dict(student_head.state_dict())\n",
    "        print(\"âœ“ Starting fresh training\")\n",
    "    \n",
    "    dino_target = DINOTarget(dim=teacher_head.mlp[-1].out_features, device=device)\n",
    "    if resume_checkpoint_path and Path(resume_checkpoint_path).exists():\n",
    "        # Restore DINO target center if available\n",
    "        if 'dino_target_center' in checkpoint:\n",
    "            dino_target.center = checkpoint['dino_target_center'].to(device)\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    # Use constant learning rate of 1e-4 (no scheduler)\n",
    "    constant_lr = 1e-4\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = constant_lr\n",
    "    \n",
    "    # Initialize plot for real-time updates\n",
    "    fig, ax1, ax2 = None, None, None\n",
    "    plot_path = None\n",
    "    if save_dir:\n",
    "        plot_path = f\"{save_dir}/training_curves.png\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        plt.ion()  # Turn on interactive mode\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)  # Track loss for plotting\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Update plot in real-time\n",
    "        if save_dir and len(losses) > 0 and fig is not None:\n",
    "            ax1.clear()\n",
    "            ax1.plot(range(1, len(losses) + 1), losses, 'b-', linewidth=2)\n",
    "            ax1.set_xlabel('Epoch', fontsize=12)\n",
    "            ax1.set_ylabel('Loss', fontsize=12)\n",
    "            ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.set_xlim([1, max(len(losses), num_epochs)])\n",
    "            \n",
    "            if len(knn_accuracies) > 0:\n",
    "                ax2.clear()\n",
    "                ax2.plot(epochs_evaluated, knn_accuracies, 'r-o', linewidth=2, markersize=6)\n",
    "                ax2.set_xlabel('Epoch', fontsize=12)\n",
    "                ax2.set_ylabel('k-NN Accuracy (%)', fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.set_xlim([1, num_epochs])\n",
    "                if len(knn_accuracies) > 0:\n",
    "                    ax2.set_ylim([0, max(100, max(knn_accuracies) * 1.1)])\n",
    "            else:\n",
    "                ax2.clear()\n",
    "                ax2.text(0.5, 0.5, 'No k-NN evaluations yet', \n",
    "                        ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "                ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "            plt.pause(0.01)  # Small pause to update display\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        # DINO paper: evaluate on teacher EMA model only, using [cls] token\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            if knn_train_loader is not None and knn_test_loader is not None:\n",
    "                knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "                knn_accuracies.append(knn_acc)\n",
    "                epochs_evaluated.append(epoch + 1)\n",
    "                print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scaler_state_dict': scaler.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'best_knn_acc': best_knn_acc,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                        'losses': losses,\n",
    "                        'knn_accuracies': knn_accuracies,\n",
    "                        'epochs_evaluated': epochs_evaluated,\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\", _use_new_zipfile_serialization=False)\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Save latest checkpoint every epoch (for resuming)\n",
    "        if save_dir:\n",
    "            latest_checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(latest_checkpoint, f\"{save_dir}/checkpoint_latest.pt\", _use_new_zipfile_serialization=False)\n",
    "        \n",
    "        # Periodic checkpoint saving (numbered checkpoints)\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'best_knn_acc': best_knn_acc,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "                'losses': losses,\n",
    "                'knn_accuracies': knn_accuracies,\n",
    "                'epochs_evaluated': epochs_evaluated,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\", _use_new_zipfile_serialization=False)\n",
    "            print(f\"  â†’ Saved checkpoint: checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Final plot update\n",
    "    if save_dir and len(losses) > 0 and fig is not None:\n",
    "        plt.ioff()  # Turn off interactive mode\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Final training curves saved to {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "    # Initialize teacher as a copy of student\n",
    "    teacher.load_state_dict(student.state_dict())\n",
    "    teacher.eval()\n",
    "    # Initialize teacher_head as a copy of student_head\n",
    "    teacher_head.load_state_dict(student_head.state_dict())\n",
    "    dino_target = DINOTarget(dim=teacher_head.mlp[-1].out_features, device=device)\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    if save_dir:\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    best_knn_acc = 0.0\n",
    "    \n",
    "    # Track losses and k-NN accuracies for plotting\n",
    "    losses = []\n",
    "    knn_accuracies = []\n",
    "    epochs_evaluated = []\n",
    "\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    num_batches = len(train_loader)\n",
    "    # Use constant learning rate of 1e-4 (no scheduler)\n",
    "    constant_lr = 1e-4\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = constant_lr\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)  # Track loss for plotting\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        # DINO paper: evaluate on teacher EMA model only, using [cls] token\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            if knn_train_loader is not None and knn_test_loader is not None:\n",
    "                knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "                knn_accuracies.append(knn_acc)\n",
    "                epochs_evaluated.append(epoch + 1)\n",
    "                print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\")\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Periodic checkpoint saving\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Plot loss and k-NN accuracy\n",
    "    if len(losses) > 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot loss\n",
    "        ax1.plot(range(1, len(losses) + 1), losses, 'b-', linewidth=2)\n",
    "        ax1.set_xlabel('Epoch', fontsize=12)\n",
    "        ax1.set_ylabel('Loss', fontsize=12)\n",
    "        ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_xlim([1, len(losses)])\n",
    "        \n",
    "        # Plot k-NN accuracy\n",
    "        if len(knn_accuracies) > 0:\n",
    "            ax2.plot(epochs_evaluated, knn_accuracies, 'r-o', linewidth=2, markersize=6)\n",
    "            ax2.set_xlabel('Epoch', fontsize=12)\n",
    "            ax2.set_ylabel('k-NN Accuracy (%)', fontsize=12)\n",
    "            ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            ax2.set_xlim([1, num_epochs])\n",
    "            ax2.set_ylim([0, max(100, max(knn_accuracies) * 1.1)])\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No k-NN evaluations yet', \n",
    "                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "            ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plot_path = f\"{save_dir}/training_curves.png\" if save_dir else \"training_curves.png\"\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Saved training curves to {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "    teacher_head.load_state_dict(student_head.state_dict())\n",
    "    dino_target = DINOTarget(dim=teacher_head.mlp[-1].out_features, device=device)\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    if save_dir:\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    best_knn_acc = 0.0\n",
    "    \n",
    "    # Track losses and k-NN accuracies for plotting\n",
    "    losses = []\n",
    "    knn_accuracies = []\n",
    "    epochs_evaluated = []\n",
    "\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    num_batches = len(train_loader)\n",
    "    # Use constant learning rate of 1e-4 (no scheduler)\n",
    "    constant_lr = 1e-4\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = constant_lr\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)  # Track loss for plotting\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        # DINO paper: evaluate on teacher EMA model only, using [cls] token\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            if knn_train_loader is not None and knn_test_loader is not None:\n",
    "                knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "                knn_accuracies.append(knn_acc)\n",
    "                epochs_evaluated.append(epoch + 1)\n",
    "                print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\")\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Periodic checkpoint saving\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Plot loss and k-NN accuracy\n",
    "    if len(losses) > 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot loss\n",
    "        ax1.plot(range(1, len(losses) + 1), losses, 'b-', linewidth=2)\n",
    "        ax1.set_xlabel('Epoch', fontsize=12)\n",
    "        ax1.set_ylabel('Loss', fontsize=12)\n",
    "        ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_xlim([1, len(losses)])\n",
    "        \n",
    "        # Plot k-NN accuracy\n",
    "        if len(knn_accuracies) > 0:\n",
    "            ax2.plot(epochs_evaluated, knn_accuracies, 'r-o', linewidth=2, markersize=6)\n",
    "            ax2.set_xlabel('Epoch', fontsize=12)\n",
    "            ax2.set_ylabel('k-NN Accuracy (%)', fontsize=12)\n",
    "            ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            ax2.set_xlim([1, num_epochs])\n",
    "            ax2.set_ylim([0, max(100, max(knn_accuracies) * 1.1)])\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No k-NN evaluations yet', \n",
    "                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "            ax2.set_title('k-NN Accuracy (Teacher)', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plot_path = f\"{save_dir}/training_curves.png\" if save_dir else \"training_curves.png\"\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Saved training curves to {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "    \n",
    "    best_knn_acc = 0.0\n",
    "\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    num_batches = len(train_loader)\n",
    "    base_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Use constant learning rate (no scheduler)\n",
    "        lr = constant_lr\n",
    "        \n",
    "        # EMA momentum scheduling (DINO paper: constant 0.996 for backbone)\n",
    "        # For stability, keep EMA constant or schedule very slowly\n",
    "        # DINO paper uses constant 0.996, but we can schedule head EMA slightly\n",
    "        # Keep backbone EMA constant at 0.996 to prevent student-teacher divergence\n",
    "        current_ema_m = ema_m  # Constant 0.996 for stability\n",
    "\n",
    "        for batch_idx, (global_crop, local_crops) in enumerate(train_loader):\n",
    "            global_crop = global_crop.to(device)\n",
    "            local_crops = [lc.to(device) for lc in local_crops]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                # Student embeddings (before projection head for KoLeo)\n",
    "                student_global_emb = student(global_crop, return_embedding=True)\n",
    "                student_global = student_head(student_global_emb)\n",
    "                # DO NOT normalize head outputs - they should be raw logits\n",
    "\n",
    "                # Teacher embeddings (no gradient)\n",
    "                with torch.no_grad():\n",
    "                    teacher_global = teacher(global_crop, return_embedding=True)\n",
    "                    teacher_global = teacher_head(teacher_global)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    teacher_probs = dino_target(teacher_global)\n",
    "                    \n",
    "                    # Diagnostic: check teacher output variance (should be > 0)\n",
    "                    if batch_idx == 0 and epoch % 20 == 0:\n",
    "                        teacher_var = teacher_global.var(dim=0).mean().item()\n",
    "                        teacher_entropy = -(teacher_probs * torch.log(teacher_probs + 1e-10)).sum(dim=1).mean().item()\n",
    "                        if epoch == 0 or epoch % 50 == 0:\n",
    "                            print(f\"    [Debug] Teacher logits var: {teacher_var:.4f}, Teacher entropy: {teacher_entropy:.4f}\")\n",
    "\n",
    "                # DINO loss for global crop\n",
    "                loss = dino_loss(student_global, teacher_probs)\n",
    "\n",
    "                # Collect embeddings for KoLeo regularization\n",
    "                embeddings_list = [student_global_emb]\n",
    "\n",
    "                # DINO loss for local crops (student only)\n",
    "                for lc in local_crops:\n",
    "                    student_local_emb = student(lc, return_embedding=True)\n",
    "                    student_local = student_head(student_local_emb)\n",
    "                    # DO NOT normalize head outputs - they should be raw logits\n",
    "                    loss += dino_loss(student_local, teacher_probs)\n",
    "                    embeddings_list.append(student_local_emb)\n",
    "                \n",
    "                loss /= (1 + len(local_crops))\n",
    "                \n",
    "                # KoLeo regularization: encourage diverse representations\n",
    "                if koleo_weight > 0:\n",
    "                    # Concatenate all embeddings (global + local crops)\n",
    "                    all_embeddings = torch.cat(embeddings_list, dim=0)  # (B*(1+num_local), embed_dim)\n",
    "                    koleo_reg = koleo_loss(all_embeddings, k=3)\n",
    "                    loss += koleo_weight * koleo_reg\n",
    "\n",
    "            # Backprop\n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(student_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # EMA update of teacher (both backbone and head) with scheduled momentum\n",
    "            update_teacher(student, teacher, student_head, teacher_head, current_ema_m)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {lr:.6f}, EMA: {current_ema_m:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # k-NN evaluation and checkpoint saving\n",
    "        knn_acc = None\n",
    "        if (epoch + 1) % knn_eval_freq == 0 or (epoch + 1) == num_epochs:\n",
    "            knn_acc = knn_evaluate(teacher, knn_train_loader, knn_test_loader, k=20, device=device)\n",
    "            print(f\"--- Epoch {epoch+1}, k-NN Accuracy (teacher): {knn_acc:.2f}% ---\")\n",
    "            \n",
    "            # Save best model\n",
    "            if knn_acc > best_knn_acc:\n",
    "                best_knn_acc = knn_acc\n",
    "                if save_dir:\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'student_state_dict': student.state_dict(),\n",
    "                        'teacher_state_dict': teacher.state_dict(),\n",
    "                        'student_head_state_dict': student_head.state_dict(),\n",
    "                        'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'knn_acc': knn_acc,\n",
    "                        'loss': avg_loss,\n",
    "                        'dino_target_center': dino_target.center.cpu(),\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"{save_dir}/best_model.pt\")\n",
    "                    print(f\"  â†’ Saved best model (k-NN: {knn_acc:.2f}%)\")\n",
    "        \n",
    "        # Periodic checkpoint saving\n",
    "        if save_dir and (epoch + 1) % save_freq == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'student_head_state_dict': student_head.state_dict(),\n",
    "                'teacher_head_state_dict': teacher_head.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'knn_acc': knn_acc,\n",
    "                'loss': avg_loss,\n",
    "                'dino_target_center': dino_target.center.cpu(),\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{save_dir}/checkpoint_epoch_{epoch+1}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hAIk-fCgrgIH"
   },
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, in_channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.mha(x, x, x)\n",
    "        return out\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.w_out = nn.Linear(hidden_dim, input_dim)\n",
    "    def forward(self, x):\n",
    "        return self.w_out(self.w1(x) * F.silu(self.w2(x)))\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(SwiGLU(embed_dim, mlp_dim), nn.Dropout(dropout))\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.attention(self.norm1(x)))\n",
    "        x = x + self.dropout(self.mlp(self.norm2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5T-JOu_jr8TO"
   },
   "outputs": [],
   "source": [
    "class DINOHead(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_dim, out_dim)\n",
    "        )\n",
    "        # Remove LayerNorm - we want raw logits, not normalized outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KB2Zc2PPr-9I"
   },
   "outputs": [],
   "source": [
    "class DINOSystem(nn.Module):\n",
    "    def __init__(self, vit_student, vit_teacher, embed_dim, out_dim=65536):\n",
    "        super().__init__()\n",
    "\n",
    "        self.student = vit_student\n",
    "        self.teacher = vit_teacher\n",
    "\n",
    "        # teacher not trained directly\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # projection heads\n",
    "        self.student_head = DINOHead(embed_dim, out_dim)\n",
    "        self.teacher_head = DINOHead(embed_dim, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLR-Sfw8r_zr"
   },
   "outputs": [],
   "source": [
    "class DINOSystem(nn.Module):\n",
    "    def __init__(self, vit_student, vit_teacher, embed_dim, out_dim=65536):\n",
    "        super().__init__()\n",
    "\n",
    "        self.student = vit_student\n",
    "        self.teacher = vit_teacher\n",
    "\n",
    "        # teacher not trained directly\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # projection heads\n",
    "        self.student_head = DINOHead(embed_dim, out_dim)\n",
    "        self.teacher_head = DINOHead(embed_dim, out_dim)\n",
    "\n",
    "\n",
    "def update_teacher(student, teacher, student_head, teacher_head, m=0.996):\n",
    "    # Update backbone parameters\n",
    "    for ps, pt in zip(student.parameters(), teacher.parameters()):\n",
    "        pt.data = m * pt.data + (1 - m) * ps.data\n",
    "    # Update projection head parameters\n",
    "    for ps, pt in zip(student_head.parameters(), teacher_head.parameters()):\n",
    "        pt.data = m * pt.data + (1 - m) * ps.data\n",
    "\n",
    "def dino_loss(student_logits, teacher_probs, student_temp=0.1):\n",
    "    student_log_probs = torch.log_softmax(student_logits / student_temp, dim=-1)\n",
    "    loss = -(teacher_probs * student_log_probs).sum(dim=-1).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bSXf0DhdrglQ"
   },
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "  def __init__(self, image_size, patch_size, in_channels, embed_dim, num_heads, mlp_dim, num_layers, num_classes, dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.patch_embedding = PatchEmbedding(image_size, patch_size, in_channels, embed_dim)\n",
    "    num_patches = (image_size // patch_size) ** 2\n",
    "    self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))\n",
    "    self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.transformer_blocks = nn.ModuleList([\n",
    "      TransformerBlock(embed_dim, num_heads, mlp_dim, dropout) for _ in range(num_layers)\n",
    "    ])\n",
    "    self.norm = nn.LayerNorm(embed_dim)\n",
    "    self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "\n",
    "  def forward(self, x, return_embedding: bool = False):\n",
    "    batch_size = x.shape[0]\n",
    "    x = self.patch_embedding(x)\n",
    "    cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "    x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "    # interpolate pos embedding if sizes don't match\n",
    "    if x.size(1) != self.pos_embedding.size(1):\n",
    "        pos_embed = self.pos_embedding[:, 1:, :].transpose(1,2)  # (1, embed_dim, num_patches)\n",
    "        H = W = int((x.size(1)-1) ** 0.5)\n",
    "        pos_embed = pos_embed.reshape(1, x.size(2), int(pos_embed.size(2) ** 0.5), int(pos_embed.size(2) ** 0.5))\n",
    "        pos_embed = F.interpolate(pos_embed, size=(H,W), mode='bicubic', align_corners=False)\n",
    "        pos_embed = pos_embed.flatten(2).transpose(1,2)\n",
    "        pos_embed = torch.cat([self.pos_embedding[:, :1, :], pos_embed], dim=1)  # prepend cls token\n",
    "    else:\n",
    "        pos_embed = self.pos_embedding\n",
    "\n",
    "    x = x + pos_embed\n",
    "    x = self.dropout(x)\n",
    "    for block in self.transformer_blocks:\n",
    "        x = block(x)\n",
    "    x = self.norm(x)\n",
    "    cls_token_output = x[:, 0]  # Extract CLS token (first token) - used for k-NN evaluation\n",
    "    if return_embedding:\n",
    "        return cls_token_output  # Return CLS token embedding only\n",
    "    logits = self.head(cls_token_output)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2v4zltmMrZu6"
   },
   "outputs": [],
   "source": [
    "# --- NEW --- k-NN Evaluation Function\n",
    "# DINO paper: evaluate on teacher EMA model, using [cls] token only\n",
    "# The return_embedding=True flag returns cls_token_output = x[:, 0]  # Extract CLS token (first token) - used for k-NN evaluation from VisionTransformer\n",
    "@torch.no_grad()\n",
    "def knn_evaluate(model, train_loader, test_loader, k, device):\n",
    "    model.eval()\n",
    "    # 1. Build feature bank using CLS token embeddings\n",
    "    # model(images, return_embedding=True) returns the CLS token (first token) from VisionTransformer\n",
    "    features_list, labels_list = [], []\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        feats = model(images, return_embedding=True)  # Returns CLS token embedding\n",
    "        feats = F.normalize(feats, dim=1)\n",
    "        features_list.append(feats.cpu())\n",
    "        labels_list.append(labels)\n",
    "    train_features = torch.cat(features_list, dim=0).numpy().astype('float32')\n",
    "    train_labels = torch.cat(labels_list, dim=0).numpy().astype('int64')\n",
    "\n",
    "    # 2. Build FAISS index\n",
    "    d = train_features.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    index.add(train_features)\n",
    "\n",
    "    total_correct, total_samples = 0, 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.numpy()\n",
    "        feats = model(images, return_embedding=True)  # Returns CLS token embedding\n",
    "        feats = F.normalize(feats, dim=1).cpu().numpy().astype('float32')\n",
    "        D, I = index.search(feats, k)\n",
    "        neighbor_labels = train_labels[I]\n",
    "        preds = []\n",
    "        for nb in neighbor_labels:\n",
    "            vals, counts = np.unique(nb, return_counts=True)\n",
    "            preds.append(vals[np.argmax(counts)])\n",
    "        preds = np.array(preds)\n",
    "        total_correct += (preds == labels).sum()\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "    return 100 * total_correct / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8f7fe42d56254be1a632df735b345c5c",
      "1064f46a401a410c915d8ef7e182b6a3",
      "7e569dbea1ac47fca32313a52f14c32b",
      "2db8e34f616046faac4c83d794bca2cd",
      "f767d98dcaf74ec381299ea796cca933",
      "6cb336ea409048d08b20b6e0e25dae1c",
      "0e9b79c7206244348bdeac0db52238bd",
      "fc08598bfd5a471cad1d10e350ed1a0f",
      "25aa3513b9824bc3a452890d2e91d9f2",
      "6c7088cda10c481ab62fa09dfe5fb14d",
      "0a58250102e44cd6b096597e3c71d8c4",
      "dba5a4e51916453cbe81364146f482d1",
      "8ef2ea9d0bea42f1ac88ab9151d8fcf7",
      "022bb7d9c9f342319650033d49aa22cb",
      "44aa8fd12b3b46eeb937af3d754d2b0e",
      "2a13f4428cef4bb994f4e3da70a7fe64",
      "cb718e5b72ee4f32a1f2c00d144f0b22",
      "39ae0694ec9a4c96b68856e50c6ab7be",
      "3c5f0c2dcbd44a0c841f293d839b3afd",
      "c4c55ef7dac242fe8201fc0561a9ff53",
      "566c9d1cb5d94bedbecfe956f37e2bce",
      "7f50e3c468784f87809f7996408cb6eb",
      "0f3221ac0cc046e4b6af8fdddce5cd5b",
      "d223a24ac5af4402b8f3941fe4b039bd",
      "f88f1164a0054e16bc3e757813fac1a9",
      "6d3653edc8404785a322b40ae535bfbb",
      "d92fed92b7414c769f133ab1a570658d",
      "5d22213bf841439697dab6beb9bd17c3",
      "eede7ca6076d41fab4b989ea634b81dd",
      "b7f46511897c4042963ece93b6ab03ca",
      "e6dab842f3344b3bba8d1a3c188f9948",
      "db6e845ad008426f86bd8d8d781f7125",
      "b9a02e1045fb4df898de3cc9dfc128d6",
      "cae393778048443492254f4a57660cbb",
      "ddccd3327a044b42b1e1b3b7ab5d2d61",
      "f201d6670cea43d38789cfcb1c258df6",
      "3e8ed6aabdaf46acb23011ceba1cd78d",
      "6298bc4063c14d6e9db7a91332274d3f",
      "d22923e1d7fe4f46aaaa7660ef4e16ad",
      "38776bec8dee4133ba8d3f61bcdabd6e",
      "ceb973d8bcc5489c8cf20974b6ae09f2",
      "0f3172ec33b0457386a182157b8e4b1e",
      "677436a6bba8484c8457aac04d628a5a",
      "9fd0962300d14e57892e3dfda8cd1a8f",
      "e79dc565c3bf40588a10e14e77a9d4ea",
      "81add9e69bc34d4e9015d21df01b145d",
      "7a438164893640afa22b3be25403b5fe",
      "1731ac6c579f46a1b87e471ac8b5688c",
      "caec7476b1ac4bd8850f701091cf5b7c",
      "e0ee114d134b4d6faa51343346c0745f",
      "1314e8858a4c46eab8e4efe80134ef38",
      "9e4c1b54e41a4fbfae983fe723b37e58",
      "20ea64e1483b487a9dc6ea8b98aa95bf",
      "1eccc85030ff43d98db20ef21d56a3ac",
      "233f13d8b3294987873ab8c9dc86f248"
     ]
    },
    "id": "lJq9_YfErR19",
    "outputId": "984f875f-1f8c-417a-c832-8abee29b4353"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/23.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 workers for DataLoaders.\n",
      "CIFAR-10 loaded. SSL Train: 50000, k-NN Train: 50000, k-NN Test: 10000\n",
      "Using device: cuda\n",
      "Total parameters: 689892, Trainable parameters: 689892\n",
      "Start Time:02:42:39\n",
      "Starting DINO training...\n",
      "Epoch [1/50], Loss: 11.0911, Time: 49.92s\n",
      "Epoch [2/50], Loss: 11.0909, Time: 48.41s\n",
      "Epoch [3/50], Loss: 11.0901, Time: 48.40s\n",
      "Epoch [4/50], Loss: 11.0898, Time: 48.27s\n",
      "Epoch [5/50], Loss: 11.0898, Time: 49.17s\n",
      "--- Epoch 5, k-NN Accuracy: 27.58% ---\n",
      "Epoch [6/50], Loss: 11.0898, Time: 48.62s\n",
      "Epoch [7/50], Loss: 11.0898, Time: 47.90s\n",
      "Epoch [8/50], Loss: 11.0898, Time: 49.10s\n",
      "Epoch [9/50], Loss: 11.0898, Time: 49.71s\n",
      "Epoch [10/50], Loss: 11.0898, Time: 48.41s\n",
      "--- Epoch 10, k-NN Accuracy: 28.63% ---\n",
      "Epoch [11/50], Loss: 11.0899, Time: 47.70s\n",
      "Epoch [12/50], Loss: 11.0899, Time: 48.43s\n",
      "Epoch [13/50], Loss: 11.0899, Time: 47.94s\n",
      "Epoch [14/50], Loss: 11.0899, Time: 48.83s\n",
      "Epoch [15/50], Loss: 11.0899, Time: 48.92s\n",
      "--- Epoch 15, k-NN Accuracy: 27.59% ---\n",
      "Epoch [16/50], Loss: 11.0899, Time: 49.59s\n",
      "Epoch [17/50], Loss: 11.0898, Time: 49.39s\n",
      "Epoch [18/50], Loss: 11.0898, Time: 50.10s\n",
      "Epoch [19/50], Loss: 11.0897, Time: 49.32s\n",
      "Epoch [20/50], Loss: 11.0897, Time: 49.35s\n",
      "--- Epoch 20, k-NN Accuracy: 29.48% ---\n",
      "Epoch [21/50], Loss: 11.0896, Time: 49.32s\n",
      "Epoch [22/50], Loss: 11.0896, Time: 48.90s\n",
      "Epoch [23/50], Loss: 11.0896, Time: 48.67s\n",
      "Epoch [24/50], Loss: 11.0896, Time: 50.01s\n",
      "Epoch [25/50], Loss: 11.0896, Time: 49.02s\n",
      "--- Epoch 25, k-NN Accuracy: 30.05% ---\n",
      "Epoch [26/50], Loss: 11.0896, Time: 49.11s\n",
      "Epoch [27/50], Loss: 11.0895, Time: 48.49s\n",
      "Epoch [28/50], Loss: 11.0895, Time: 48.64s\n",
      "Epoch [29/50], Loss: 11.0895, Time: 49.11s\n",
      "Epoch [30/50], Loss: 11.0895, Time: 48.46s\n",
      "--- Epoch 30, k-NN Accuracy: 30.26% ---\n",
      "Epoch [31/50], Loss: 11.0895, Time: 49.59s\n",
      "Epoch [32/50], Loss: 11.0895, Time: 48.36s\n",
      "Epoch [33/50], Loss: 11.0895, Time: 48.96s\n",
      "Epoch [34/50], Loss: 11.0895, Time: 49.11s\n",
      "Epoch [35/50], Loss: 11.0895, Time: 49.39s\n",
      "--- Epoch 35, k-NN Accuracy: 30.80% ---\n",
      "Epoch [36/50], Loss: 11.0895, Time: 49.29s\n",
      "Epoch [37/50], Loss: 11.0895, Time: 49.02s\n",
      "Epoch [38/50], Loss: 11.0895, Time: 48.40s\n",
      "Epoch [39/50], Loss: 11.0895, Time: 49.30s\n",
      "Epoch [40/50], Loss: 11.0895, Time: 49.01s\n",
      "--- Epoch 40, k-NN Accuracy: 31.66% ---\n",
      "Epoch [41/50], Loss: 11.0895, Time: 48.87s\n",
      "Epoch [42/50], Loss: 11.0895, Time: 49.52s\n",
      "Epoch [43/50], Loss: 11.0895, Time: 48.69s\n",
      "Epoch [44/50], Loss: 11.0895, Time: 48.87s\n",
      "Epoch [45/50], Loss: 11.0895, Time: 49.09s\n",
      "--- Epoch 45, k-NN Accuracy: 32.88% ---\n",
      "Epoch [46/50], Loss: 11.0895, Time: 48.99s\n",
      "Epoch [47/50], Loss: 11.0895, Time: 48.64s\n",
      "Epoch [48/50], Loss: 11.0895, Time: 49.60s\n",
      "Epoch [49/50], Loss: 11.0895, Time: 49.79s\n",
      "Epoch [50/50], Loss: 11.0895, Time: 50.56s\n",
      "--- Epoch 50, k-NN Accuracy: 33.17% ---\n",
      "End Time:03:24:51\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Additional imports needed for main execution\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    from torchvision.datasets import STL10, CIFAR10\n",
    "    import copy\n",
    "\n",
    "    ################################################################################\n",
    "    ############################# DATASET SETUP ####################################\n",
    "    ################################################################################\n",
    "\n",
    "    # Load competition pretraining dataset from HuggingFace\n",
    "    image_size = 96  # Competition requirement: 96x96 images\n",
    "    \n",
    "    print(\"Loading competition pretraining dataset from HuggingFace...\")\n",
    "    print(\"Dataset: tsbpp/fall2025_deeplearning (pretrain split)\")\n",
    "    \n",
    "    # Load the pretraining dataset (unlabeled)\n",
    "    pretrain_dataset = load_dataset(\"tsbpp/fall2025_deeplearning\", \"pretrain\", split=\"train\")\n",
    "    \n",
    "    print(f\"Loaded {len(pretrain_dataset)} unlabeled images for pretraining\")\n",
    "    print(f\"Dataset features: {pretrain_dataset.features}\")\n",
    "    \n",
    "    # For evaluation, we still need CIFAR-10/STL-10 for k-NN evaluation during training\n",
    "    # (or you can skip k-NN evaluation during training and only evaluate on CUB-200)\n",
    "    print(\"\\nLoading CIFAR-10 + STL-10 for k-NN evaluation during training...\")\n",
    "    cifar10_root = '/tmp/cifar10'\n",
    "    cifar10_train = CIFAR10(root=cifar10_root, train=True, download=True, transform=None)\n",
    "    cifar10_test = CIFAR10(root=cifar10_root, train=False, download=True, transform=None)\n",
    "    \n",
    "    stl10_root = '/tmp/stl10'\n",
    "    stl10_train = STL10(root=stl10_root, split='train', download=True, transform=None)\n",
    "    stl10_test = STL10(root=stl10_root, split='test', download=True, transform=None)\n",
    "    \n",
    "    from torch.utils.data import ConcatDataset\n",
    "    knn_train_ds = ConcatDataset([cifar10_train, stl10_train])\n",
    "    knn_test_ds = ConcatDataset([cifar10_test, stl10_test])\n",
    "    \n",
    "    print(f\"k-NN evaluation dataset: {len(knn_train_ds)} train, {len(knn_test_ds)} test samples\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # DINO-style SSL dataset\n",
    "    # ----------------------------\n",
    "    class DINODataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, hf_dataset, image_size=96, num_local_crops=4):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                hf_dataset: HuggingFace dataset (returns dict with 'image' key)\n",
    "                image_size: Target image size\n",
    "                num_local_crops: Number of local crops per image\n",
    "            \"\"\"\n",
    "            self.dataset = hf_dataset\n",
    "            self.num_local_crops = num_local_crops\n",
    "            \n",
    "            # Global crop transforms (DINO-style augmentations)\n",
    "            global_transforms = [\n",
    "                transforms.RandomResizedCrop(image_size, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "                transforms.RandomGrayscale(p=0.2),\n",
    "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0))], p=0.5),\n",
    "                transforms.RandomApply([transforms.RandomSolarize(threshold=128, p=1.0)], p=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ]\n",
    "            self.global_transform = transforms.Compose(global_transforms)\n",
    "            \n",
    "            # Local crop transforms\n",
    "            local_transforms = [\n",
    "                transforms.RandomResizedCrop(image_size, scale=(0.14, 0.5)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "                transforms.RandomGrayscale(p=0.2),\n",
    "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0))], p=0.5),\n",
    "                transforms.RandomApply([transforms.RandomSolarize(threshold=128, p=1.0)], p=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ]\n",
    "            self.local_transform = transforms.Compose(local_transforms)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dataset)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # HuggingFace dataset returns dict with 'image' key (PIL Image)\n",
    "            item = self.dataset[idx]\n",
    "            img = item['image']\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Resize to ensure minimum size for cropping\n",
    "            if min(img.size) < image_size:\n",
    "                img = transforms.Resize(image_size, interpolation=InterpolationMode.BICUBIC)(img)\n",
    "            \n",
    "            # Apply transforms\n",
    "            global_crop = self.global_transform(img)\n",
    "            local_crops = [self.local_transform(img) for _ in range(self.num_local_crops)]\n",
    "            \n",
    "            return global_crop, local_crops\n",
    "\n",
    "    # Create SSL dataset from HuggingFace pretraining data\n",
    "    ssl_ds_train = DINODataset(pretrain_dataset, image_size=image_size, num_local_crops=4)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Evaluation datasets (k-NN)\n",
    "    # ----------------------------\n",
    "    # CIFAR-10 needs resizing, STL-10 doesn't\n",
    "    eval_transform_cifar = transforms.Compose([\n",
    "        transforms.Resize(image_size, interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    eval_transform_stl = transforms.Compose([\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # For evaluation, we need to recreate the datasets with the eval transform\n",
    "    # Combine both CIFAR-10 and STL-10 for k-NN evaluation\n",
    "    knn_cifar10_train = CIFAR10(root=cifar10_root, train=True, download=False, transform=eval_transform_cifar)\n",
    "    knn_cifar10_test = CIFAR10(root=cifar10_root, train=False, download=False, transform=eval_transform_cifar)\n",
    "    knn_stl10_train = STL10(root=stl10_root, split='train', download=False, transform=eval_transform_stl)\n",
    "    knn_stl10_test = STL10(root=stl10_root, split='test', download=False, transform=eval_transform_stl)\n",
    "    \n",
    "    knn_train_ds = ConcatDataset([knn_cifar10_train, knn_stl10_train])\n",
    "    knn_test_ds = ConcatDataset([knn_cifar10_test, knn_stl10_test])\n",
    "\n",
    "    # ----------------------------\n",
    "    # DataLoaders\n",
    "    # ----------------------------\n",
    "    num_cores = os.cpu_count() or 2\n",
    "    print(f\"Using {num_cores} workers for DataLoaders.\")\n",
    "\n",
    "    # SMALL GPU VERSION: Reduced batch size for limited GPU memory\n",
    "    # DINO authors: LR is most sensitive hyperparameter, scale with batch size\n",
    "    # Smaller batch sizes need proportionally smaller learning rates\n",
    "    batch_size = 32  # SMALL GPU VERSION: Reduced for limited GPU memory\n",
    "    train_loader = DataLoader(ssl_ds_train, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_cores, pin_memory=True)\n",
    "    knn_train_loader = DataLoader(knn_train_ds, batch_size=batch_size, shuffle=False,\n",
    "                                  num_workers=num_cores, pin_memory=True)\n",
    "    knn_test_loader = DataLoader(knn_test_ds, batch_size=batch_size, shuffle=False,\n",
    "                                 num_workers=num_cores, pin_memory=True)\n",
    "\n",
    "    dataset_name = \"Competition Pretraining Dataset (HuggingFace)\"\n",
    "    print(f\"{dataset_name} loaded. SSL Train: {len(ssl_ds_train)}, k-NN Train: {len(knn_train_ds)}, k-NN Test: {len(knn_test_ds)}\")\n",
    "\n",
    "    ################################################################################\n",
    "    ############################# MODEL SETUP ######################################\n",
    "    ################################################################################\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # --- Vision Transformer student + teacher ---\n",
    "    # SMALL GPU VERSION: Reduced parameters for limited GPU memory\n",
    "    # With 96x96 images: patch_size=8 gives 144 patches (vs 576 with patch_size=4)\n",
    "    embed_dim = 256  # SMALL GPU VERSION: Reduced from 512\n",
    "    model = VisionTransformer(\n",
    "        image_size=image_size,  # 96x96 for competition\n",
    "        patch_size=8,  # SMALL GPU VERSION: Larger patches = fewer: (96/8)^2 = 144 patches\n",
    "        in_channels=3,\n",
    "        embed_dim=embed_dim,\n",
    "        num_heads=8,    # embed_dim must be divisible by num_heads (256/8 = 32)\n",
    "        mlp_dim=1024,   # SMALL GPU VERSION: Reduced (4x embed_dim)\n",
    "        num_layers=6,  # SMALL GPU VERSION: Reduced from 12\n",
    "        num_classes=100,  # not used for SSL\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    student = model\n",
    "    teacher = copy.deepcopy(student)\n",
    "    teacher.eval()\n",
    "\n",
    "    # --- Projection heads ---\n",
    "    # DINO paper: use >=65k prototypes for best results\n",
    "    # Using 65536 (2^16) for optimal performance - this is critical for stability\n",
    "    projection_dim = 65536\n",
    "    student_head = DINOHead(in_dim=embed_dim, out_dim=projection_dim).to(device)\n",
    "    teacher_head = DINOHead(in_dim=embed_dim, out_dim=projection_dim).to(device)\n",
    "\n",
    "    # --- Optimizer ---\n",
    "    # Use constant learning rate of 1e-4 (no scheduler, no batch size scaling)\n",
    "    learning_rate = 1e-4\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        list(student.parameters()) + list(student_head.parameters()),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=0.04,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    print(f\"Using constant learning rate: {learning_rate:.6f}\")\n",
    "\n",
    "    total_params = sum(p.numel() for p in student.parameters())\n",
    "    trainable_params = sum(p.numel() for p in student.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params}, Trainable parameters: {trainable_params}\")\n",
    "\n",
    "    ################################################################################\n",
    "    ############################# TRAINING ########################################\n",
    "    ################################################################################\n",
    "\n",
    "    print(\"Start Time:\" + time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    print(\"Starting DINO training...\")\n",
    "\n",
    "    # DINO paper trains for 300 epochs on ImageNet\n",
    "    # For CIFAR-10, we'll use 200 epochs (smaller dataset needs fewer epochs)\n",
    "    # Optional: Resume from a specific checkpoint\n",
    "    # Set resume_from=None to start fresh, or provide path like \"./checkpoints/checkpoint_latest.pt\"\n",
    "    resume_from = None  # Change to checkpoint path if you want to resume from a specific checkpoint\n",
    "    \n",
    "    train_dino(\n",
    "        train_loader,\n",
    "        student,\n",
    "        teacher,\n",
    "        student_head,\n",
    "        teacher_head,\n",
    "        optimizer,\n",
    "        device=device,\n",
    "        num_epochs=200,  # DINO paper uses 300, but smaller datasets need fewer epochs\n",
    "        ema_m=0.996,\n",
    "        knn_eval_freq=20,\n",
    "        warmup_epochs=10,  # Not used anymore (constant LR), but kept for compatibility\n",
    "        save_dir=\"./checkpoints\",  # Save checkpoints here\n",
    "        save_freq=10,  # Save checkpoint every 10 epochs\n",
    "        koleo_weight=0.1,  # DINOv2: KoLeo regularization weight (0.1 is a good default)\n",
    "        knn_train_loader=knn_train_loader,  # Pass k-NN loaders for evaluation\n",
    "        knn_test_loader=knn_test_loader,\n",
    "        resume_from=resume_from  # Resume from checkpoint if interrupted\n",
    "    )\n",
    "\n",
    "    print(\"End Time:\" + time.strftime(\"%H:%M:%S\", time.localtime()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-NmjQB2rbLZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}